{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f08eca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# This will download MNIST into ./data if it's not already there\n",
    "train = datasets.MNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "test  = datasets.MNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "029d4cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "MLPClassifier(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "batch_size = 128\n",
    "val_size = 5000\n",
    "train_size = len(train) - val_size\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_subset, val_subset = random_split(train, [train_size, val_size], generator=generator)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=28*28, hidden_dims=(256, 128), num_classes=10):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, num_classes))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLPClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bbe7972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss 0.4065, train acc 0.8846 | val loss 0.1872, val acc 0.9438 | time 6.23s\n",
      "Epoch 2: train loss 0.1615, train acc 0.9513 | val loss 0.1275, val acc 0.9610 | time 6.17s\n",
      "Epoch 3: train loss 0.1142, train acc 0.9652 | val loss 0.1070, val acc 0.9676 | time 6.16s\n",
      "Epoch 4: train loss 0.0921, train acc 0.9715 | val loss 0.0916, val acc 0.9724 | time 7.07s\n",
      "Epoch 5: train loss 0.0743, train acc 0.9773 | val loss 0.0821, val acc 0.9746 | time 7.16s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.perf_counter()\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "    epoch_time = time.perf_counter() - start_time\n",
    "    print(\n",
    "        f\"Epoch {epoch}: train loss {train_loss:.4f}, train acc {train_acc:.4f} | \"\n",
    "        f\"val loss {val_loss:.4f}, val acc {val_acc:.4f} | time {epoch_time:.2f}s\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42101338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ONNX model to mnist_mlp.onnx\n"
     ]
    }
   ],
   "source": [
    "# Export trained model to ONNX\n",
    "onnx_path = \"mnist_mlp.onnx\"\n",
    "model.eval()\n",
    "dummy_input = torch.randn(1, 1, 28, 28, device=device)\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch\"}, \"logits\": {0: \"batch\"}},\n",
    "    opset_version=12,\n",
    "    do_constant_folding=True,\n",
    ")\n",
    "print(f\"Saved ONNX model to {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ee541e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'aimet_onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maimet_onnx\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maimet_onnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantizationSimModel\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maimet_onnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantScheme\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'aimet_onnx'"
     ]
    }
   ],
   "source": [
    "# AIMET ONNX PTQ (calibration-based)\n",
    "import numpy as np\n",
    "import onnx\n",
    "import aimet_onnx\n",
    "from aimet_onnx import QuantizationSimModel\n",
    "from aimet_onnx.common.defs import QuantScheme\n",
    "\n",
    "# Load exported ONNX model\n",
    "model_onnx = onnx.load(onnx_path)\n",
    "\n",
    "# Optional: simplify ONNX graph\n",
    "try:\n",
    "    import onnxsim\n",
    "    model_onnx, _ = onnxsim.simplify(model_onnx)\n",
    "    print(\"ONNX model simplified\")\n",
    "except Exception as e:\n",
    "    print(\"onnxsim not available or simplification failed:\", e)\n",
    "\n",
    "# Create QuantSim model (W8A16)\n",
    "providers = [\"CPUExecutionProvider\"]\n",
    "sim = QuantizationSimModel(\n",
    "    model_onnx,\n",
    "    param_type=aimet_onnx.int8,\n",
    "    activation_type=aimet_onnx.int16,\n",
    "    quant_scheme=QuantScheme.min_max,\n",
    "    config_file=\"default\",\n",
    "    providers=providers,\n",
    ")\n",
    "\n",
    "input_name = sim.session.get_inputs()[0].name\n",
    "NUM_CALIBRATION_SAMPLES = 1024\n",
    "num_batches = max(1, NUM_CALIBRATION_SAMPLES // batch_size)\n",
    "\n",
    "def onnx_data_generator(num_batches):\n",
    "    for i, (data, _) in enumerate(train_loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        yield {input_name: data.numpy()}\n",
    "\n",
    "# Compute encodings using calibration data (train subset only)\n",
    "sim.compute_encodings(onnx_data_generator(num_batches))\n",
    "\n",
    "def eval_onnx_session(session, loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in loader:\n",
    "        outputs = session.run(None, {input_name: inputs.numpy()})[0]\n",
    "        preds = outputs.argmax(axis=1)\n",
    "        correct += (preds == labels.numpy()).sum()\n",
    "        total += labels.shape[0]\n",
    "    return correct / total\n",
    "\n",
    "val_acc_quant = eval_onnx_session(sim.session, val_loader)\n",
    "print(f\"Quantized (W8A16) validation accuracy: {val_acc_quant:.4f}\")\n",
    "\n",
    "# Export quantized model and encodings\n",
    "export_path = \".\"\n",
    "export_prefix = \"mnist_mlp_w8a16\"\n",
    "sim.export(export_path, export_prefix, export_model=True)\n",
    "print(f\"Exported quantized model to {export_prefix}.onnx and encodings file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5f4519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test on quantized ONNX model (CPU timing)\n",
    "import onnxruntime as ort\n",
    "import time\n",
    "\n",
    "quant_onnx_path = \"mnist_mlp_w8a16.onnx\"\n",
    "sess = ort.InferenceSession(quant_onnx_path, providers=[\"CPUExecutionProvider\"])\n",
    "input_name = sess.get_inputs()[0].name\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "test_acc_quant = eval_onnx_session(sess, test_loader)\n",
    "test_time_quant = time.perf_counter() - start_time\n",
    "print(f\"Quantized ONNX test acc: {test_acc_quant:.4f} | time {test_time_quant:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3ac2f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test: loss 0.0720, acc 0.9763 | time 0.47s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
    "test_time = time.perf_counter() - start_time\n",
    "print(f\"Final test: loss {test_loss:.4f}, acc {test_acc:.4f} | time {test_time:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
